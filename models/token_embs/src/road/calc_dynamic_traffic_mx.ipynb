{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../../../..\")\n",
    "from pipelines.utils import ROOT_DIR, load_road_network\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "city = \"porto\"\n",
    "edge_df, _, _, LG = load_road_network(city_name=city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(os.path.join(ROOT_DIR,\"datasets/trajectory\",city,\"train/train_{}.parquet\".format(123),))\n",
    "val = pd.read_parquet(os.path.join(ROOT_DIR,\"datasets/trajectory\",city,\"val/val_{}.parquet\".format(123),))\n",
    "data = pd.concat([train, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speed_features(df, edge_df) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generates features containing average speed, utilization and accelaration\n",
    "        for each edge i.e road segment.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: features in shape num_edges x features\n",
    "        \"\"\"\n",
    "        rdf = pd.DataFrame({\"id\": edge_df.fid}, index=edge_df.index)\n",
    "        # calculate utilization on each edge which is defined as the count an edge is traversed by all trajectories\n",
    "        seg_seqs = df[\"cpath\"].values\n",
    "        counter = Counter()\n",
    "        for seq in seg_seqs:\n",
    "            counter.update(Counter(seq))\n",
    "\n",
    "        rdf[\"util\"] = rdf.id.map(counter)\n",
    "\n",
    "\n",
    "        speed_counter, count_counter = calc_avg_speed(df)\n",
    "        for j in range(1, 25):\n",
    "            rdf[f\"avg_speed_{j}\"] = rdf.id.map(\n",
    "                {\n",
    "                    k: (float(speed_counter[j][k]) / count_counter[j][k]) * 111000 * 3.6\n",
    "                    for k in speed_counter[j]\n",
    "                }\n",
    "            )\n",
    "        return rdf\n",
    "\n",
    "\n",
    "def calc_avg_speed(data: pd.DataFrame):\n",
    "    cpaths = data[\"cpath\"].values\n",
    "    opaths = data[\"opath\"].values\n",
    "    speeds = data[\"speed\"].values\n",
    "    times = data[\"timestamps\"].values\n",
    "    \n",
    "    # Create a defaultdict of Counters for each hour\n",
    "    speed_counters = defaultdict(Counter)\n",
    "    count_counters = defaultdict(Counter)\n",
    "    \n",
    "    for opath, cpath, speed, time_stamps in tqdm(zip(opaths, cpaths, speeds, times), total=len(speeds)):\n",
    "        last_lidx, last_ridx = 0, 0\n",
    "        for l, r, s, t in zip(opath[0::1], opath[1::1], speed, time_stamps):\n",
    "            t_hour = datetime.fromtimestamp(t).hour\n",
    "            \n",
    "            if s * 111000 * 3.6 >= 200:  # check unrealistic speed values\n",
    "                continue\n",
    "            \n",
    "            lidxs, ridxs = np.where(cpath == l)[0], np.where(cpath == r)[0]\n",
    "            lidx = lidxs[lidxs >= last_lidx][0]\n",
    "            ridx = ridxs[(ridxs >= last_ridx) & (ridxs >= lidx)][0]\n",
    "            \n",
    "            assert lidx <= ridx\n",
    "            traversed_edges = cpath[lidx : ridx + 1]\n",
    "            \n",
    "            # Update the counters for the specific hour\n",
    "            speed_counters[t_hour].update(dict(zip(traversed_edges, [s] * len(traversed_edges))))\n",
    "            count_counters[t_hour].update(dict(zip(traversed_edges, [1] * len(traversed_edges))))\n",
    "            \n",
    "            last_lidx, last_ridx = lidx, ridx\n",
    "    \n",
    "    return speed_counters, count_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = generate_speed_features(data, edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate NaN values in the specified columns\n",
    "avg_speed_columns = [f'avg_speed_{i}' for i in range(1, 25)]\n",
    "out[avg_speed_columns] = out[avg_speed_columns].interpolate(axis=1, method='linear', limit_direction='both')\n",
    "out[avg_speed_columns] = out[avg_speed_columns].fillna(method='bfill', axis=1).fillna(method='ffill', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all remaining NaN values with 40\n",
    "out[avg_speed_columns] = out[avg_speed_columns].fillna(40)\n",
    "# Set speed values below 10 to 10\n",
    "out[avg_speed_columns] = out[avg_speed_columns].clip(lower=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as parquet\n",
    "out.to_parquet(os.path.join(ROOT_DIR,\"datasets/transition\",city,\"traffic_mx.parquet\",))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
