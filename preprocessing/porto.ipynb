{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pipelines.utils import PLAIN_DATASET_NAME, PRE_MAP_DATASET_NAME, ROOT_DIR, DATASET_NAME, PEPROCESSED_DATASET_NAME, load_road_network\n",
    "from preprocessing.utils import PREPROCESS_MAP\n",
    "\n",
    "from preprocessing.rs_mapping import create_road_mapping_df, post_processing_mapped_df, merge_preprocessed_and_fmm\n",
    "\n",
    "from preprocessing.cell_mapping import clean_and_output_data\n",
    "from preprocessing.visualize import plot_gps_traj, plot_cpath\n",
    "from pipelines.utils import load_config, generate_train_test_split, generate_train_val_test_split\n",
    "\n",
    "config = load_config(name=\"porto\", ctype=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Preprocessing ###\n",
    "\n",
    "We start with plain_dataset.parquet, which is the original data set as downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original dataset\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], PLAIN_DATASET_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_preprocessing = False # Makes a Linestring from POLYLINE, add coords column, timestamps column\n",
    "if need_preprocessing:\n",
    "        df = PREPROCESS_MAP[config[\"city\"]](df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = clean_and_output_data(df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.to_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], PRE_MAP_DATASET_NAME)\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_preprocessed dataset\n",
    "df_preprocessed = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], PRE_MAP_DATASET_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_road_mapping_df(df_preprocessed, config[\"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to map match with fmm. See mapping.sh for how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fmm = pd.read_csv(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], \"mr.txt\"), delimiter=\";\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_preprocessed_and_fmm(df_preprocessed, df_fmm)\n",
    "df = post_processing_mapped_df(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], PEPROCESSED_DATASET_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], PEPROCESSED_DATASET_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For final dataset, select only necessary columns\n",
    "df = df[['TAXI_ID', 'coord_seq', 'opath', 'timestamps', 'cpath', 'speed', 'road_timestamps']]\n",
    "\n",
    "# Convert weired array(array([...]))) to list of lists [[...]] -> does not work, after loading still array of arrays\n",
    "#df['merc_seq'] = df['merc_seq'].apply(lambda x: [list(y) for y in x])\n",
    "#df['coord_seq'] = df['coord_seq'].apply(lambda x: [list(y) for y in x])\n",
    "\n",
    "# For classification Task we need to transform TAXI_ID to numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['TAXI_ID'] = le.fit_transform(df['TAXI_ID'])\n",
    "df[\"TAXI_ID\"].max()\n",
    "\n",
    "\n",
    "df.to_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], DATASET_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "df = pd.read_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], DATASET_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into train, val, test\n",
    "train, val, test = generate_train_val_test_split(config['city'], config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train, val, test\n",
    "train.to_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], \"train\", f\"train_{config['seed']}.parquet\")\n",
    ")\n",
    "val.to_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], \"val\", f\"val_{config['seed']}.parquet\")\n",
    ")\n",
    "test.to_parquet(\n",
    "    os.path.join(ROOT_DIR, \"datasets/trajectory\", config[\"city\"], \"test\", f\"test_{config['seed']}.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.cpath[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.coord_seq[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.opath[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_coord_seq = [coord_seq[i] for i in range(len(opath)) if opath[i] in target_path]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot GPS Traj and Road Seg. Traj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3    \n",
    "traj = df.coord_seq[idx]\n",
    "traj = [[y, x] for x, y in traj]\n",
    "cpath = df.cpath[idx]\n",
    "opath = df.opath[idx]\n",
    "\n",
    "\n",
    "# Test printing on map\n",
    "edge_df, nodes_df, G, LG = load_road_network(config[\"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gps_traj(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpath(opath, edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "def plot_cpath(cpath, edge_df, zoom=14, width=1000, height=500, tiles='cartodbpositron'):\n",
    "    linestrings = edge_df.iloc[list(cpath)]['geometry'].reset_index(drop=True)\n",
    "\n",
    "    # Create a GeoDataFrame with the LINESTRING data\n",
    "    gdf = gpd.GeoDataFrame(geometry=linestrings)\n",
    "\n",
    "    # Obtain lat_center and lon_center\n",
    "    bounds = gdf.total_bounds\n",
    "    lat_center = (bounds[1] + bounds[3]) / 2\n",
    "    lon_center = (bounds[0] + bounds[2]) / 2\n",
    "\n",
    "    # Create a Folium map\n",
    "    f = folium.Figure(width=width, height=height)\n",
    "    map = folium.Map(location=(lat_center, lon_center), zoom_start=zoom, tiles=tiles).add_to(f)\n",
    "\n",
    "    # Add the LINESTRINGs to the map\n",
    "    for _, row in gdf.iterrows():\n",
    "        folium.PolyLine(\n",
    "            locations=[(lat, lon) for lon, lat in row['geometry'].coords]\n",
    "        ).add_to(map)\n",
    "\n",
    "    # Display the map\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gps_traj(coords, zoom=14, width=1000, height=500, tiles='cartodbpositron'):\n",
    "    # Calculate the center of the trajectory\n",
    "    lat_center = sum([coord[0] for coord in coords])/len(coords)\n",
    "    lon_center = sum([coord[1] for coord in coords])/len(coords)\n",
    "\n",
    "    # Create a map object centered on the trajectory\n",
    "    f = folium.Figure(width=width, height=height)\n",
    "    map = folium.Map(location=(lat_center, lon_center), zoom_start=zoom, tiles=tiles).add_to(f)\n",
    "\n",
    "    # Plot the coordinates on the map\n",
    "    for coord in coords:\n",
    "        folium.CircleMarker(location=coord, radius=2).add_to(map)\n",
    "\n",
    "    # Return the map object\n",
    "    return f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSMNx Network tests ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges, gdf_nodes, G, line_G = load_road_network(\"porto\")\n",
    "import osmnx as ox\n",
    "G = ox.graph_from_place('Porto, Portugal')\n",
    "fig, ax = ox.plot_graph(G, node_color='b', node_zorder=3)\n",
    "\n",
    "G2 = ox.speed.add_edge_speeds(G)\n",
    "G2 = ox.speed.add_edge_travel_times(G2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
